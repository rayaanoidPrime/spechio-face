{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "df32cb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "48e077e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import shutil\n",
    "\n",
    "dataset_path = \"C:\\\\Users\\\\Rayaan_Ghosh\\\\Desktop\\\\spechio-face\\\\ML\\\\skin-dataset\"\n",
    "oily_path = os.path.join(dataset_path , \"oily\")\n",
    "dry_path = os.path.join(dataset_path , \"dry\")\n",
    "subfolder_paths = [os.path.join(dataset_path , \"train\") ,os.path.join(dataset_path , \"test\") ]\n",
    "\n",
    "train_ratio = 0.8\n",
    "\n",
    "for path in subfolder_paths:\n",
    "    os.makedirs(path)\n",
    "    os.makedirs(os.path.join(path,\"oily\"), exist_ok=True) #skin_dataset/train/oily  , skin_dataset/test/oily\n",
    "    os.makedirs(os.path.join(path,\"dry\") , exist_ok=True) #skin_dataset/train/dry , skin_dataset/test/dry\n",
    "\n",
    "for p in [oily_path , dry_path]:\n",
    "    files = os.listdir(p)\n",
    "    random.shuffle(files)\n",
    "\n",
    "    split_index = int(train_ratio * len(files))\n",
    "    train_files = files[:split_index]\n",
    "    test_files = files[split_index:]\n",
    "    directory, filename = os.path.split(p)\n",
    "    for file in train_files:\n",
    "        file_path = os.path.join(p, file)\n",
    "        destination_path = os.path.join(os.path.join(subfolder_paths[0] , filename ), file)\n",
    "        shutil.move(file_path, destination_path)\n",
    "\n",
    "    # Move the test files to the test subfolder\n",
    "    for file in test_files:\n",
    "        file_path = os.path.join(p, file)\n",
    "        destination_path = os.path.join(os.path.join(subfolder_paths[1] , filename ), file)\n",
    "        shutil.move(file_path, destination_path)\n",
    "    \n",
    "        \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cdd40503",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 411 images belonging to 2 classes.\n",
      "Found 103 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Preprocess data (get all of the pixel values between 0 & 1, also called scaling/normalization)\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Setup paths to our data directories\n",
    "train_dir = subfolder_paths[0]\n",
    "test_dir = subfolder_paths[1]\n",
    "\n",
    "# Import data from directories and turn it into batches\n",
    "train_data = train_datagen.flow_from_directory(directory=train_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               seed=42)\n",
    "valid_data = valid_datagen.flow_from_directory(directory=test_dir,\n",
    "                                               target_size=(224, 224),\n",
    "                                               class_mode=\"categorical\",\n",
    "                                               seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "19348c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "efficientnet_url = \"https://tfhub.dev/tensorflow/efficientnet/b0/feature-vector/1\"\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "\n",
    "def create_model(model_url, num_classes=3):\n",
    "    \n",
    "    \"\"\"\n",
    "    Takes a TensorFlow Hub URL and creates a Keras Sequential model with it.\n",
    "\n",
    "    Args:\n",
    "    model_url(str): A TensorFlow Hub feature extraction URL.\n",
    "    num_classes(int): Number of output neurons in the output layer, \n",
    "      should be equal to number of target classes, default = 10\n",
    "\n",
    "    Returns:\n",
    "    An uncompiled Keras Sequential model with model_url as feature extractor \n",
    "    layer and Dense output layer with num_classes output neurons.\n",
    "    \"\"\"\n",
    "    # Download the pretrained model and save it as a Keras layer\n",
    "    feature_extractor_layer = hub.KerasLayer(model_url,\n",
    "                                           trainable = False,   # freeze the already learned patterns\n",
    "                                           name=\"EfficientnetB0_model\",\n",
    "                                           input_shape=IMAGE_SHAPE+(3,))  # define the input image shape\n",
    "    # Create our image model\n",
    "    model = tf.keras.Sequential([   \n",
    "        feature_extractor_layer,    # use the feature extraction layer as the base\n",
    "        layers.Dense(num_classes, activation=\"softmax\", name=\"output_layer\")   # create our own output layer\n",
    "    ])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e1022bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create EfficientNet model\n",
    "efficientnet_model = create_model(efficientnet_url,\n",
    "                            num_classes=2)\n",
    "# Compile\n",
    "efficientnet_model.compile(loss=\"categorical_crossentropy\",\n",
    "                     optimizer=tf.keras.optimizers.Adam(),\n",
    "                     metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5fab5e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " EfficientnetB0_model (Keras  (None, 1280)             4049564   \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,052,126\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 4,049,564\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "efficientnet_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0537ec00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "13/13 [==============================] - 75s 3s/step - loss: 0.3539 - accuracy: 0.8613 - val_loss: 0.2576 - val_accuracy: 0.8738\n",
      "Epoch 2/5\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.1914 - accuracy: 0.9562 - val_loss: 0.1805 - val_accuracy: 0.9417\n",
      "Epoch 3/5\n",
      "13/13 [==============================] - 34s 3s/step - loss: 0.1445 - accuracy: 0.9611 - val_loss: 0.1495 - val_accuracy: 0.9515\n",
      "Epoch 4/5\n",
      "13/13 [==============================] - 35s 3s/step - loss: 0.1208 - accuracy: 0.9708 - val_loss: 0.1324 - val_accuracy: 0.9515\n",
      "Epoch 5/5\n",
      "13/13 [==============================] - 36s 3s/step - loss: 0.1079 - accuracy: 0.9757 - val_loss: 0.1191 - val_accuracy: 0.9612\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "efficientnet_history = efficientnet_model.fit(train_data,\n",
    "                                  epochs=5,\n",
    "                                  validation_data=valid_data)   # name of log files\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d657fc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Function `_wrapped_model` contains input name(s) EfficientnetB0_model_input with unsupported characters which will be renamed to efficientnetb0_model_input in the SavedModel.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: saved_model/my_model\\assets\n"
     ]
    }
   ],
   "source": [
    "efficientnet_model.save('saved_model/my_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e5a265",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " EfficientnetB0_model (Keras  (None, 1280)             4049564   \n",
      " Layer)                                                          \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,052,126\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 4,049,564\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('saved_model/my_model')\n",
    "\n",
    "# Check its architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23a426f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dry' 'oily']\n"
     ]
    }
   ],
   "source": [
    "train_dir = \"C:\\\\Users\\\\Rayaan_Ghosh\\\\Desktop\\\\spechio-face\\\\ML\\\\skin-dataset\\\\train\"\n",
    "import pathlib \n",
    "data_dir = pathlib.Path(train_dir)\n",
    "class_names = np.array(sorted([item.name for item in data_dir.glob('*')]))\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfa26cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to import an image and resize it to be able to be used with our model\n",
    "def load_and_prep_image(filename, img_shape=224):\n",
    "    \"\"\"\n",
    "    Reads in an image from filename, turns it into a tensor and reshapes into (224,224,3).\n",
    "    \"\"\"\n",
    "    # Read in the image\n",
    "    img = tf.io.read_file(filename)\n",
    "    # Decode it into a tensor\n",
    "    img = tf.image.decode_jpeg(img)\n",
    "    # Resize the image\n",
    "    img = tf.image.resize(img, [img_shape, img_shape])\n",
    "    # Rescale the image (get all values between 0 and 1)\n",
    "    img = img/255.\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d952e19a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconfig pred_and_plot function to work with multi-class images\n",
    "def pred_and_plot(model, filename, class_names=class_names):\n",
    "    \"\"\"\n",
    "    Imports an image located at filename, makes a prediction with model\n",
    "    and plots the image with the predicted class as the title.\n",
    "    \"\"\"\n",
    "    # Import the target image and preprocess it\n",
    "    img = load_and_prep_image(filename)\n",
    "\n",
    "    # Make a prediction\n",
    "    pred = model.predict(tf.expand_dims(img, axis=0))\n",
    "\n",
    "    # Add in logic for multi-class & get pred_class name\n",
    "    if len(pred[0]) > 1:\n",
    "        pred_class = class_names[tf.argmax(pred[0])]\n",
    "    else:\n",
    "        pred_class = class_names[int(tf.round(pred[0]))]\n",
    "\n",
    "    print('Prediction Probabilities : ', pred[0])\n",
    "\n",
    "    # Plot the image and predicted class\n",
    "    plt.imshow(img)\n",
    "    plt.title(f\"Prediction: {pred_class}\")\n",
    "    plt.axis(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dddc221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 2s 2s/step\n",
      "Prediction Probabilities :  [0.9504036  0.04959644]\n"
     ]
    }
   ],
   "source": [
    "img1 = \"C:\\\\Users\\\\Rayaan_Ghosh\\\\Desktop\\\\spechio-face\\\\ML\\\\skin-tone\\\\test_imgs\\\\test_1.jpg\"\n",
    "img2 = \"C:\\\\Users\\\\Rayaan_Ghosh\\\\Pictures\\\\Camera Roll\\\\WIN_20230629_14_33_03_Pro.jpg\"\n",
    "\n",
    "pred_and_plot(model=model, \n",
    "              filename=img1, \n",
    "              class_names=class_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c93a331",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
